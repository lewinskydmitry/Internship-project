{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('src'), '..')))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim.lr_scheduler as lr\n",
    "\n",
    "seed_value = 42\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from src.Trainer.Trainer import Trainer\n",
    "from src.Models.Classifiers import *\n",
    "from src.Trainer.Model_class import Model_class\n",
    "from src.Trainer.Loss_class import Loss_class\n",
    "\n",
    "from src.Models.Autoencoders import *\n",
    "from src.Models.JoinedModel import JoinedModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_PARAM = 512\n",
    "LATENT_REPR = 5\n",
    "\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/df_to_enc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_test(X_data, y_data, test_ratio):\n",
    "    # Prepare dataset for testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_data,\n",
    "                                                     y_data,\n",
    "                                                     shuffle = True,\n",
    "                                                     stratify = y_data,\n",
    "                                                     random_state = 42,\n",
    "                                                     test_size = test_ratio)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_enc(X_data, y_data, autoenc_requared):\n",
    "\n",
    "    # Check that amount rows for enc less than length of data\n",
    "    if autoenc_requared >= len(X_data):\n",
    "        raise ValueError(\"The number of rows for autoencoder more than amount of X_train data\")\n",
    "    \n",
    "    autoenc_ratio = autoenc_requared/len(X_data)\n",
    "    \n",
    "    X_to_enc, X_to_clas,\\\n",
    "    y_to_enc, y_to_clas = train_test_split(X_data,\n",
    "                                           y_data,\n",
    "                                           shuffle = True,\n",
    "                                           stratify = y_data,\n",
    "                                           random_state = 42,\n",
    "                                           train_size = autoenc_ratio)\n",
    "    \n",
    "    X_train, X_test = train_test_split(X_to_enc,\n",
    "                                       shuffle = True,\n",
    "                                       random_state = 42,\n",
    "                                       train_size = 0.9)\n",
    "    \n",
    "    return X_train, X_test, X_to_clas, y_to_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_classif(X_data, y_data, classif_requared):\n",
    "\n",
    "    # Prepare dataset for encoder\n",
    "    if classif_requared >= len(X_data):\n",
    "        raise ValueError(\"The number of rows for classifier more than amount of X_train data\")\n",
    "    classif_ratio = classif_requared / len(X_data)\n",
    "    \n",
    "    X_train, X_test,\\\n",
    "    y_train, y_test = train_test_split(X_data,\n",
    "                                       y_data,\n",
    "                                       shuffle = True,\n",
    "                                       stratify = y_data,\n",
    "                                       random_state = 42,\n",
    "                                       train_size = classif_ratio)\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(*data, encoder_data = False):\n",
    "    \n",
    "    if len(data) > 1:\n",
    "        data_list = [data[i] for i in range(len(data))]\n",
    "        dataset = pd.concat(data_list, axis = 1)\n",
    "    else:\n",
    "        dataset = data[0]\n",
    "    if encoder_data == False:\n",
    "        dataset = TableDatasetDF(dataset)\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=True,\n",
    "            generator=generator\n",
    "        )\n",
    "    else:\n",
    "        dataset = EncoderDataset(dataset)\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=True,\n",
    "            generator=generator\n",
    "        )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(X_data, y_data, test_ratio, autoenc_requared, classif_requared):\n",
    "    X_train, X_test, y_train, y_test = prepare_data_for_test(X_data, y_data, test_ratio)\n",
    "    X_encoder_train, X_encoder_test, X_to_clas, y_to_clas = prepare_data_for_enc(X_train, y_train, autoenc_requared)\n",
    "    X_train_classif, y_train_classif = prepare_data_for_classif(X_to_clas, y_to_clas, classif_requared)\n",
    "\n",
    "    test_dl = make_dataloader(X_test, y_test)\n",
    "    train_dl = make_dataloader(X_train_classif, y_train_classif)\n",
    "\n",
    "    enc_train_dl = make_dataloader(X_encoder_train, encoder_data=True)\n",
    "    enc_test_dl = make_dataloader(X_encoder_test, encoder_data=True)\n",
    "\n",
    "    return train_dl, test_dl, enc_train_dl, enc_test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dl,\\\n",
    "# test_dl, enc_train_dl, enc_test_dl = prepare_data(df.drop(columns = ['Machine failure']),\n",
    "#                                                   df['Machine failure'], 0.2, 6000, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cycle(df, list_amount = [50, 100, 500, 1000, 1999]):\n",
    "    for labels_amount in list_amount:\n",
    "        ############################################################\n",
    "        # PREPARE DATA\n",
    "        ############################################################\n",
    "        train_dl, test_dl, enc_train_dl, enc_test_dl = prepare_data(df.drop(columns = ['Machine failure']),\n",
    "                                                                    df['Machine failure'], 0.2, 6000, labels_amount)\n",
    "\n",
    "        ############################################################\n",
    "        # TRAIN AUTOENCODER\n",
    "        ############################################################\n",
    "        # Set training settings\n",
    "        autoencoder = Autoencoder(enc_train_dl.dataset.data.shape[1], HIDDEN_PARAM, LATENT_REPR)\n",
    "        loss = Encoder_loss(nn.MSELoss())\n",
    "        model_factory = partial(Model_class)\n",
    "        optimizer_factory = partial(torch.optim.AdamW)\n",
    "        scheduler_factory = partial(lr.ExponentialLR)\n",
    "\n",
    "        model_params = dict(model=autoencoder,\n",
    "                            device=device)\n",
    "\n",
    "        optimizer_params = dict(weight_decay=1e-3, lr=1e-2)\n",
    "        scheduler_params = dict(gamma=0.95)\n",
    "\n",
    "        learning_params = dict(batch_size=BATCH_SIZE, num_epoch=30)\n",
    "\n",
    "        wandb_init_params = dict(\n",
    "            name=f'Autoencoder_simple_HidParam-{HIDDEN_PARAM}_Latent-{LATENT_REPR}',\n",
    "            project=\"Internship_project\",\n",
    "            dir = '../logs/'\n",
    "        )\n",
    "        # Start training\n",
    "        trainer = Trainer(enc_train_dl,\n",
    "                          enc_test_dl,\n",
    "                          loss,\n",
    "                          model_factory=model_factory,\n",
    "                          optimizer_factory=optimizer_factory,\n",
    "                          scheduler_factory=scheduler_factory,\n",
    "                          model_params=model_params,\n",
    "                          optimizer_params=optimizer_params,\n",
    "                          scheduler_params=scheduler_params,\n",
    "                          log=False,\n",
    "                          wandb_init_params=wandb_init_params,\n",
    "                          model_dir='../logs/nn_models/autoencoder/',\n",
    "                          saving_model=False\n",
    "                          )\n",
    "        trainer.train_model(learning_params)\n",
    "        wandb.finish()\n",
    "\n",
    "        ############################################################\n",
    "        # TRAIN CLASSIFIER\n",
    "        ############################################################\n",
    "        \n",
    "        classifier = Simple_classifier(train_dl.dataset.data.shape[1], 50)\n",
    "        jm = JoinedModel(trainer.model.model.encoder, classifier)\n",
    "\n",
    "        loss = Loss_class(FocalLoss(gamma=3))\n",
    "        model_factory = partial(Model_class)\n",
    "        optimizer_factory = partial(torch.optim.AdamW)\n",
    "        scheduler_factory = partial(lr.ExponentialLR)\n",
    "\n",
    "        model_params = dict(model=jm,\n",
    "                            device=device)\n",
    "\n",
    "        optimizer_params = dict(weight_decay=1e-3, lr=1e-2)\n",
    "        scheduler_params = dict(gamma=0.95)\n",
    "\n",
    "        learning_params = dict(batch_size=BATCH_SIZE, num_epoch=20)\n",
    "\n",
    "        wandb_init_params = dict(\n",
    "            name=f'JM_NumLab-{labels_amount}_LatDim-{LATENT_REPR}',\n",
    "            project=\"Internship_project\",\n",
    "            dir = '../logs/'\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(train_dl,\n",
    "                          test_dl,\n",
    "                          loss,\n",
    "                          model_factory=model_factory,\n",
    "                          optimizer_factory=optimizer_factory,\n",
    "                          scheduler_factory=scheduler_factory,\n",
    "                          model_params=model_params,\n",
    "                          optimizer_params=optimizer_params,\n",
    "                          scheduler_params=scheduler_params,\n",
    "                          log=True,\n",
    "                          wandb_init_params=wandb_init_params,\n",
    "                          model_dir='../logs/nn_models/joined_models/',\n",
    "                          saving_model=False\n",
    "                          )\n",
    "        \n",
    "        trainer.train_model(learning_params)\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmitrii_fomin\u001b[0m (\u001b[33mdmitrii_fomin_uga\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../logs/wandb\\run-20230529_204528-eihcpvy1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmitrii_fomin_uga/Internship_project/runs/eihcpvy1' target=\"_blank\">Autoencoder_simple_HidParam-512_Latent-5</a></strong> to <a href='https://wandb.ai/dmitrii_fomin_uga/Internship_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmitrii_fomin_uga/Internship_project' target=\"_blank\">https://wandb.ai/dmitrii_fomin_uga/Internship_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmitrii_fomin_uga/Internship_project/runs/eihcpvy1' target=\"_blank\">https://wandb.ai/dmitrii_fomin_uga/Internship_project/runs/eihcpvy1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 of 30, 0.043 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 91.34it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 121.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 of 30, 0.002 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 74.00it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 120.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 80.88it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 of 30, 0.002 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 80.31it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 169.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 100.18it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 116.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 104.31it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 77.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 91.93it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 186.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 of 30, 0.002 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 76.41it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 120.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 of 30, 0.002 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 82.03it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 118.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 79.55it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 191.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 66.83it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 61.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 of 30, 0.002 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 43.46it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 60.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 of 30, 0.003 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 67.22it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 119.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 of 30, 0.002 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 73.17it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 97.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 of 30, 0.002 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 82.05it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 113.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 81.99it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 80.62it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 118.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 of 30, 0.002 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 78.30it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 81.80it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 123.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 82.62it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 102.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 101.07it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 89.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 82.20it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 124.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 83.68it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 153.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 91.26it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 96.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 84.05it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 122.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 56.90it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 of 30, 0.002 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 90.52it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 95.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 92.92it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<00:00, 123.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 of 30, 0.001 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 6/6 [00:00<00:00, 68.59it/s]\n",
      "Let's see how good I am...: 100%|██████████| 1/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 of 30, 0.002 min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>lr</td><td>██▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>█▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>29</td></tr><tr><td>lr</td><td>0.00215</td></tr><tr><td>test_loss</td><td>0.01815</td></tr><tr><td>train_loss</td><td>0.02045</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Autoencoder_simple_HidParam-512_Latent-5</strong> at: <a href='https://wandb.ai/dmitrii_fomin_uga/Internship_project/runs/eihcpvy1' target=\"_blank\">https://wandb.ai/dmitrii_fomin_uga/Internship_project/runs/eihcpvy1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../logs/wandb\\run-20230529_204528-eihcpvy1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../logs/wandb\\run-20230529_204538-6f06bu0w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dmitrii_fomin_uga/Internship_project/runs/6f06bu0w' target=\"_blank\">JM_NumLab-50_LatDim-5</a></strong> to <a href='https://wandb.ai/dmitrii_fomin_uga/Internship_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dmitrii_fomin_uga/Internship_project' target=\"_blank\">https://wandb.ai/dmitrii_fomin_uga/Internship_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dmitrii_fomin_uga/Internship_project/runs/6f06bu0w' target=\"_blank\">https://wandb.ai/dmitrii_fomin_uga/Internship_project/runs/6f06bu0w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I'm studying hard now🧐, don't disturb!: 100%|██████████| 1/1 [00:00<00:00, 83.93it/s]\n",
      "Let's see how good I am...: 100%|██████████| 2/2 [00:00<00:00, 41.66it/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] Клиент не обладает требуемыми правами: 'd:\\\\Github\\\\Internship-project\\\\logs\\\\nn_models\\\\joined_models\\\\JM_NumLab-50_LatDim-5_state_dict.pth' -> '../logs/wandb\\\\run-20230529_204538-6f06bu0w\\\\files\\\\nn_models\\\\joined_models\\\\JM_NumLab-50_LatDim-5_state_dict.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_cycle(df)\n",
      "Cell \u001b[1;32mIn[10], line 91\u001b[0m, in \u001b[0;36mtrain_cycle\u001b[1;34m(df, list_amount)\u001b[0m\n\u001b[0;32m     70\u001b[0m wandb_init_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m     71\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mJM_NumLab-\u001b[39m\u001b[39m{\u001b[39;00mlabels_amount\u001b[39m}\u001b[39;00m\u001b[39m_LatDim-\u001b[39m\u001b[39m{\u001b[39;00mLATENT_REPR\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[0;32m     72\u001b[0m     project\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInternship_project\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     73\u001b[0m     \u001b[39mdir\u001b[39m \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../logs/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     74\u001b[0m )\n\u001b[0;32m     76\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(train_dl,\n\u001b[0;32m     77\u001b[0m                   test_dl,\n\u001b[0;32m     78\u001b[0m                   loss,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m                   saving_model\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     89\u001b[0m                   )\n\u001b[1;32m---> 91\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain_model(learning_params)\n\u001b[0;32m     92\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[1;32md:\\Github\\Internship-project\\src\\Trainer\\Trainer.py:108\u001b[0m, in \u001b[0;36mTrainer.train_model\u001b[1;34m(self, learning_params)\u001b[0m\n\u001b[0;32m    106\u001b[0m     torch\u001b[39m.\u001b[39msave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mstate_dict(), log_path)\n\u001b[0;32m    107\u001b[0m     model_artifact\u001b[39m.\u001b[39madd_file(log_path)\n\u001b[1;32m--> 108\u001b[0m     wandb\u001b[39m.\u001b[39;49msave(log_path, base_path \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwandb_init_params[\u001b[39m'\u001b[39;49m\u001b[39mdir\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    110\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun\u001b[39m.\u001b[39mlog_artifact(model_artifact)\n\u001b[0;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_metrics(epoch\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m    112\u001b[0m                     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_to_update, \n\u001b[0;32m    113\u001b[0m                     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mval_to_update, \n\u001b[0;32m    114\u001b[0m                     lr\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mget_last_lr()[\u001b[39m0\u001b[39m]\n\u001b[0;32m    115\u001b[0m                    )\n",
      "File \u001b[1;32mc:\\Users\\dimaf\\miniconda3\\envs\\torch\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:345\u001b[0m, in \u001b[0;36m_run_decorator._noop_on_finish.<locals>.decorator_fn.<locals>.wrapper_fn\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    343\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper_fn\u001b[39m(\u001b[39mself\u001b[39m: Type[\u001b[39m\"\u001b[39m\u001b[39mRun\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    344\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_is_finished\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 345\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    347\u001b[0m     default_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    348\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRun (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid\u001b[39m}\u001b[39;00m\u001b[39m) is finished. The call to `\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` will be ignored. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    349\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPlease make sure that you are using an active run.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    350\u001b[0m     )\n\u001b[0;32m    351\u001b[0m     resolved_message \u001b[39m=\u001b[39m message \u001b[39mor\u001b[39;00m default_message\n",
      "File \u001b[1;32mc:\\Users\\dimaf\\miniconda3\\envs\\torch\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:335\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    334\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_is_attaching \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 335\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dimaf\\miniconda3\\envs\\torch\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:1783\u001b[0m, in \u001b[0;36mRun.save\u001b[1;34m(self, glob_str, base_path, policy)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     deprecate\u001b[39m.\u001b[39mdeprecate(\n\u001b[0;32m   1775\u001b[0m         field_name\u001b[39m=\u001b[39mdeprecate\u001b[39m.\u001b[39mDeprecated\u001b[39m.\u001b[39mrun__save_no_args,\n\u001b[0;32m   1776\u001b[0m         warning_message\u001b[39m=\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1779\u001b[0m         ),\n\u001b[0;32m   1780\u001b[0m     )\n\u001b[0;32m   1781\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m-> 1783\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save(glob_str, base_path, policy)\n",
      "File \u001b[1;32mc:\\Users\\dimaf\\miniconda3\\envs\\torch\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:1837\u001b[0m, in \u001b[0;36mRun._save\u001b[1;34m(self, glob_str, base_path, policy)\u001b[0m\n\u001b[0;32m   1835\u001b[0m         os\u001b[39m.\u001b[39msymlink(abs_path, wandb_path)\n\u001b[0;32m   1836\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(wandb_path):\n\u001b[1;32m-> 1837\u001b[0m         os\u001b[39m.\u001b[39;49msymlink(abs_path, wandb_path)\n\u001b[0;32m   1838\u001b[0m     files\u001b[39m.\u001b[39mappend(wandb_path)\n\u001b[0;32m   1839\u001b[0m \u001b[39mif\u001b[39;00m warn:\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1314] Клиент не обладает требуемыми правами: 'd:\\\\Github\\\\Internship-project\\\\logs\\\\nn_models\\\\joined_models\\\\JM_NumLab-50_LatDim-5_state_dict.pth' -> '../logs/wandb\\\\run-20230529_204538-6f06bu0w\\\\files\\\\nn_models\\\\joined_models\\\\JM_NumLab-50_LatDim-5_state_dict.pth'"
     ]
    }
   ],
   "source": [
    "train_cycle(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
